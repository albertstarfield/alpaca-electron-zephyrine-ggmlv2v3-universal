--- engine.py
+++ engine.py
@@ -849,9 +849,6 @@
     def cached_inference(self, prompt, slot, context_type):
         """Checks if a similar prompt exists in the database using fuzzy matching."""
         
-        # Ensure sequential execution by waiting if LLM is running
-        while self.is_llm_running: #Wait if LLM busy
-            time.sleep(0.1)
 
         db_cursor = self.database_manager.db_cursor
 
